import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Activation, MaxPooling2D, Flatten, Dropout
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt

def load_data():
  """ 
  生成训练数据和
  """
  c_vs_d_dataset = '../../dataset/cats_and_dogs_small'
  # 输入目录的路径，并生成批量的增强/标准化的数据。
  train_datagen = image.ImageDataGenerator(
    rescale=1.0/255, # 标准化数据，默认为 None。如果是 None 或 0，不进行缩放，否则将数据乘以所提供的值（在应用任何其他转换之前）
    rotation_range=40, # 随机旋转的度数范围
    width_shift_range=0.2, # 进行水平位移
    height_shift_range=0.2, # 进行垂直位移
    shear_range=0.2, # 剪切强度（以弧度逆时针方向剪切角度）
    zoom_range=0.2, # 随机缩放范围
    horizontal_flip=True, # 随机水平翻转
    fill_mode='nearest'
    )
  test_datagen = image.ImageDataGenerator( rescale=1.0/255 )
  # 训练数据
  train_flow = train_datagen.flow_from_directory(directory=c_vs_d_dataset + '/train', target_size=(150, 150), batch_size=32, class_mode='binary')

  # 验证数据
  val_flow = test_datagen.flow_from_directory(directory=c_vs_d_dataset + '/validation', target_size=(150, 150), batch_size=32, class_mode='binary')
  return train_flow, val_flow


def createModel():
  # 搭建网络
  model = Sequential()

  # 第一层
  model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3)))
  model.add(MaxPooling2D(pool_size=(2, 2)))

  model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))
  model.add(MaxPooling2D(pool_size=(2, 2)))

  model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))
  model.add(MaxPooling2D(pool_size=(2, 2)))

  model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))
  model.add(MaxPooling2D(pool_size=(2, 2)))

  model.add(Flatten())
  model.add(Dropout(0.5))
  model.add(Dense(512, activation='relu'))
  model.add(Dense(1, activation='sigmoid'))

  model.summary()

  return model

def train():
  train_generator, val_generator = load_data()
  model = createModel()
  model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])
  history = model.fit_generator(train_generator, epochs=100, validation_data=val_generator)
  model.save('c_vs_d_small.h5')

  print(history.history.keys())
  acc = history.history['acc']
  val_acc = history.history['val_acc']
  loss = history.history['loss']
  val_loss = history.history['val_loss']

  print('--------------------------------------- acc', acc)
  print('--------------------------------------- val_acc', val_acc)
  print('--------------------------------------- loss', loss)
  print('--------------------------------------- val_loss', val_loss)

  # plt.plot(range(1, len(acc) + 1), acc, 'bo', label='training acc')
  # plt.plot(range(1, len(val_acc) + 1), val_acc, 'b', label='validation acc')
  # plt.title('training and validation acc')
  # plt.legend()

  # plt.figure()

  # plt.plot(range(1, len(loss) + 1), loss, 'bo', label='training loss')
  # plt.plot(range(1, len(val_loss) + 1), val_loss, 'b', label='validation loss')
  # plt.title('training and validation loss')
  # plt.legend()

  # plt.show()

def showHistory():
  acc = [0.5180000066757202, 0.5364999771118164, 0.578000009059906, 0.5964999794960022, 0.6255000233650208, 0.6480000019073486, 0.6349999904632568, 0.659500002861023, 0.6600000262260437, 0.6725000143051147, 0.6825000047683716, 0.6865000128746033, 0.6974999904632568, 0.6865000128746033, 0.6930000185966492, 0.7089999914169312, 0.7045000195503235, 0.7080000042915344, 0.7204999923706055, 0.7310000061988831, 0.7200000286102295, 0.7250000238418579, 0.7269999980926514, 0.7254999876022339, 0.7354999780654907, 0.7304999828338623, 0.7394999861717224, 0.7419999837875366, 0.7595000267028809, 0.7599999904632568, 0.7565000057220459, 0.7735000252723694, 0.7559999823570251, 0.7720000147819519, 0.762499988079071, 0.7649999856948853, 0.7785000205039978, 0.7919999957084656, 0.7754999995231628, 0.7850000262260437, 0.7860000133514404, 0.7889999747276306, 0.796999990940094, 0.7904999852180481, 0.7954999804496765, 0.8025000095367432, 0.7979999780654907, 0.800000011920929, 0.800000011920929, 0.7954999804496765, 0.7910000085830688, 0.7875000238418579, 0.8059999942779541, 0.8009999990463257, 0.8130000233650208, 0.8140000104904175, 0.8050000071525574, 0.8144999742507935, 0.8100000023841858, 0.8029999732971191, 0.8109999895095825, 0.8209999799728394, 0.8119999766349792, 0.8240000009536743, 0.8140000104904175, 0.8100000023841858, 0.8220000267028809, 0.8134999871253967, 0.8065000176429749, 0.8295000195503235, 0.8224999904632568, 0.8215000033378601, 0.828499972820282, 0.8199999928474426, 0.8389999866485596, 0.8264999985694885, 0.8220000267028809, 0.8220000267028809, 0.8309999704360962, 0.8374999761581421, 0.8379999995231628, 0.8299999833106995, 0.8324999809265137, 0.8330000042915344, 0.8270000219345093, 0.8479999899864197, 0.8305000066757202, 0.8504999876022339, 0.8374999761581421, 0.8224999904632568, 0.8370000123977661, 0.8305000066757202, 0.8535000085830688, 0.8519999980926514, 0.8374999761581421, 0.8374999761581421, 0.8460000157356262, 0.8535000085830688, 0.8450000286102295, 0.8424999713897705]
  val_acc = [0.5040000081062317, 0.6110000014305115, 0.5189999938011169, 0.6050000190734863, 0.6620000004768372, 0.6359999775886536, 0.6650000214576721, 0.6869999766349792, 0.6990000009536743, 0.6859999895095825, 0.7129999995231628, 0.7260000109672546, 0.6819999814033508, 0.703000009059906, 0.6420000195503235, 0.7429999709129333, 0.7620000243186951, 0.7120000123977661, 0.6959999799728394, 0.7379999756813049, 0.7329999804496765, 0.7820000052452087, 0.7440000176429749, 0.7620000243186951, 0.7850000262260437, 0.7829999923706055, 0.753000020980835, 0.781000018119812, 0.7429999709129333, 0.781000018119812, 0.7929999828338623, 0.796999990940094, 0.7570000290870667, 0.8040000200271606, 0.8059999942779541, 0.7940000295639038, 0.7409999966621399, 0.7519999742507935, 0.7860000133514404, 0.800000011920929, 0.7850000262260437, 0.7870000004768372, 0.7940000295639038, 0.7950000166893005, 0.7919999957084656, 0.8029999732971191, 0.7910000085830688, 0.8230000138282776, 0.8159999847412109, 0.7990000247955322, 0.8069999814033508, 0.8270000219345093, 0.8299999833106995, 0.8140000104904175, 0.8199999928474426, 0.8109999895095825, 0.828000009059906, 0.8349999785423279, 0.8029999732971191, 0.7900000214576721, 0.8299999833106995, 0.8240000009536743, 0.8069999814033508, 0.8460000157356262, 0.843999981880188, 0.8190000057220459, 0.843999981880188, 0.7540000081062317, 0.8209999799728394, 0.8149999976158142, 0.8410000205039978, 0.8370000123977661, 0.8389999866485596, 0.8059999942779541, 0.871999979019165, 0.8299999833106995, 0.8349999785423279, 0.8379999995231628, 0.843999981880188, 0.796999990940094, 0.7900000214576721, 0.8360000252723694, 0.8289999961853027, 0.8159999847412109, 0.8600000143051147, 0.8109999895095825, 0.8389999866485596, 0.8610000014305115, 0.8429999947547913, 0.8270000219345093, 0.8529999852180481, 0.8130000233650208, 0.8320000171661377, 0.8700000047683716, 0.8450000286102295, 0.8650000095367432, 0.8140000104904175, 0.8299999833106995, 0.8629999756813049, 0.8500000238418579]
  loss = [0.7080783247947693, 0.6920193433761597, 0.6830539107322693, 0.6691401600837708, 0.6355279684066772, 0.6383177638053894, 0.6433907151222229, 0.6239866614341736, 0.6110931038856506, 0.6126099824905396, 0.5994684100151062, 0.619486391544342, 0.5713094472885132, 0.6112120747566223, 0.5773864388465881, 0.5652915239334106, 0.5696377754211426, 0.5657097697257996, 0.5533275008201599, 0.5473431348800659, 0.5545978546142578, 0.5484325885772705, 0.5402522683143616, 0.5422715544700623, 0.5445014238357544, 0.5241230726242065, 0.5489165186882019, 0.512565553188324, 0.504240870475769, 0.5147005319595337, 0.501152753829956, 0.49920859932899475, 0.4927176237106323, 0.4836151599884033, 0.501129686832428, 0.4931395351886749, 0.4799826443195343, 0.46408531069755554, 0.48790743947029114, 0.4645403027534485, 0.48158106207847595, 0.45592552423477173, 0.4497929513454437, 0.4596847891807556, 0.44854679703712463, 0.4438357353210449, 0.4486435353755951, 0.44596365094184875, 0.4411284327507019, 0.4474673271179199, 0.4435744285583496, 0.4452020823955536, 0.4417691230773926, 0.4393450915813446, 0.4210253059864044, 0.42552614212036133, 0.4216524362564087, 0.4237334430217743, 0.43032461404800415, 0.4220738410949707, 0.4217391908168793, 0.4139291048049927, 0.42892950773239136, 0.40686628222465515, 0.4167943298816681, 0.4159441292285919, 0.4168555736541748, 0.40705394744873047, 0.419617623090744, 0.3977639079093933, 0.383918821811676, 0.4183741509914398, 0.3905220329761505, 0.39984554052352905, 0.39709097146987915, 0.3854251801967621, 0.41121137142181396, 0.40463927388191223, 0.3968033492565155, 0.3822750747203827, 0.376778781414032, 0.3959290385246277, 0.38761067390441895, 0.385822594165802, 0.40508347749710083, 0.36493995785713196, 0.3853631019592285, 0.37878739833831787, 0.37165290117263794, 0.41439181566238403, 0.37041032314300537, 0.378252238035202, 0.34885674715042114, 0.34839269518852234, 0.372314989566803, 0.37907513976097107, 0.3660561144351959, 0.36974772810935974, 0.36003822088241577, 0.37543240189552307]
  val_loss = [0.6998289823532104, 0.6617490649223328, 0.7246770262718201, 0.6462633609771729, 0.618048906326294, 0.6397905945777893, 0.6085906624794006, 0.5874013304710388, 0.5687650442123413, 0.5633143186569214, 0.5625755786895752, 0.5301439762115479, 0.6306183338165283, 0.5704196095466614, 0.6644559502601624, 0.530518114566803, 0.49324238300323486, 0.554072380065918, 0.6116092801094055, 0.5150964260101318, 0.49630558490753174, 0.4562833309173584, 0.5178664326667786, 0.5061367154121399, 0.46283629536628723, 0.4584078788757324, 0.4862251877784729, 0.4414999485015869, 0.5113527774810791, 0.4509860575199127, 0.45301198959350586, 0.43992605805397034, 0.4897588789463043, 0.44143247604370117, 0.4444904029369354, 0.4604754149913788, 0.5029275417327881, 0.6463962197303772, 0.4680970311164856, 0.43354278802871704, 0.48365968465805054, 0.4742749035358429, 0.4308825135231018, 0.43094518780708313, 0.476285457611084, 0.3997073471546173, 0.44411998987197876, 0.4004286527633667, 0.4211450517177582, 0.4514690637588501, 0.42126938700675964, 0.40081796050071716, 0.39868679642677307, 0.40778565406799316, 0.3859853744506836, 0.39744147658348083, 0.408509761095047, 0.41822418570518494, 0.48946553468704224, 0.4597168564796448, 0.4245423674583435, 0.4015144109725952, 0.4258008301258087, 0.37154141068458557, 0.3743166923522949, 0.49199333786964417, 0.3583774268627167, 0.5913664102554321, 0.40618860721588135, 0.4184315800666809, 0.3926726281642914, 0.3672753870487213, 0.3674921989440918, 0.4357384443283081, 0.33604007959365845, 0.4000117778778076, 0.4051990807056427, 0.3726862668991089, 0.3853544592857361, 0.44983989000320435, 0.4689785838127136, 0.41271141171455383, 0.4000132977962494, 0.4157837927341461, 0.3572460114955902, 0.45677071809768677, 0.36372777819633484, 0.34596455097198486, 0.38045045733451843, 0.4376898407936096, 0.3711370825767517, 0.5365379452705383, 0.39849528670310974, 0.38421431183815, 0.4445250332355499, 0.3718520402908325, 0.4857529103755951, 0.4464758336544037, 0.5284703969955444, 0.3653499186038971]

  plt.plot(range(1, len(acc) + 1), acc, 'bo', label='training acc')
  plt.plot(range(1, len(val_acc) + 1), val_acc, 'b', label='validation acc')
  plt.title('training and validation acc')
  plt.legend()

  plt.figure()

  plt.plot(range(1, len(loss) + 1), loss, 'bo', label='training loss')
  plt.plot(range(1, len(val_loss) + 1), val_loss, 'b', label='validation loss')
  plt.title('training and validation loss')
  plt.legend()

  plt.show()

def showHistory2():
  acc = [0.5110294222831726, 0.5152310729026794, 0.555672287940979, 0.5477941036224365, 0.5877100825309753, 0.6081932783126831, 0.6486344337463379, 0.6391806602478027, 0.6365545988082886, 0.6670168042182922, 0.6538865566253662, 0.6706932783126831, 0.6780462265014648, 0.6875, 0.6780462265014648, 0.6922268867492676, 0.7016806602478027, 0.6843487620353699, 0.7195377945899963, 0.7127100825309753, 0.7153361439704895, 0.7247899174690247, 0.7043067216873169, 0.7158613204956055, 0.7211134433746338, 0.7153361439704895, 0.7352941036224365, 0.7158613204956055, 0.7494747638702393, 0.7405462265014648, 0.7410714030265808, 0.7452731132507324, 0.7447478771209717, 0.7457982897758484, 0.7473739385604858, 0.7536764740943909, 0.7584033608436584, 0.7515756487846375, 0.7505252361297607, 0.7778361439704895, 0.7620798349380493, 0.7668067216873169, 0.7636554837226868, 0.786239504814148, 0.7647058963775635, 0.7752100825309753, 0.7657563090324402, 0.7878151535987854, 0.7710084319114685, 0.7715336084365845, 0.7935924530029297, 0.7932291626930237, 0.7883403301239014, 0.7736344337463379, 0.7867646813392639, 0.8019958138465881, 0.796875, 0.8014705777168274, 0.7998949289321899, 0.7867646813392639, 0.7878151535987854, 0.8077731132507324, 0.7956932783126831, 0.8156512379646301, 0.815625011920929, 0.805672287940979, 0.8151260614395142, 0.8172268867492676, 0.8051470518112183, 0.8125, 0.8198529481887817, 0.8019958138465881, 0.8088235259056091, 0.7972689270973206, 0.8140756487846375, 0.8040966391563416, 0.8098739385604858, 0.8130252361297607, 0.825630247592926, 0.8172268867492676, 0.8266806602478027, 0.8182772994041443, 0.8240545988082886, 0.8230041861534119, 0.8156512379646301, 0.8293067216873169, 0.8277310729026794, 0.8198529481887817, 0.8293067216873169, 0.8282563090324402, 0.8219537734985352, 0.8371848464012146, 0.8277310729026794, 0.832457959651947, 0.8251050710678101, 0.8303571343421936, 0.8261554837226868, 0.8413865566253662, 0.8308823704719543, 0.8356092572212219]
  val_acc = [0.49687498807907104, 0.5458333492279053, 0.6135416626930237, 0.6239583492279053, 0.6156250238418579, 0.625, 0.5708333253860474, 0.6739583611488342, 0.6333333253860474, 0.6822916865348816, 0.7093750238418579, 0.7197916507720947, 0.5104166865348816, 0.7093750238418579, 0.6854166388511658, 0.7177083492279053, 0.746874988079071, 0.6760416626930237, 0.7260416746139526, 0.7333333492279053, 0.746874988079071, 0.7302083373069763, 0.6989583373069763, 0.7854166626930237, 0.7270833253860474, 0.7239583134651184, 0.7552083134651184, 0.7739583253860474, 0.7906249761581421, 0.7864583134651184, 0.6552083492279053, 0.7729166746139526, 0.7947916388511658, 0.6572916507720947, 0.7645833492279053, 0.7729166746139526, 0.7427083253860474, 0.8041666746139526, 0.7906249761581421, 0.7614583373069763, 0.7197916507720947, 0.7989583611488342, 0.715624988079071, 0.8020833134651184, 0.7895833253860474, 0.7718750238418579, 0.7635416388511658, 0.6760416626930237, 0.8125, 0.7791666388511658, 0.8125, 0.768750011920929, 0.7604166865348816, 0.7489583492279053, 0.8052083253860474, 0.815625011920929, 0.7770833373069763, 0.8072916865348816, 0.8083333373069763, 0.8270833492279053, 0.7124999761581421, 0.8125, 0.8125, 0.8197916746139526, 0.8333333134651184, 0.8135416507720947, 0.7666666507720947, 0.8177083134651184, 0.8125, 0.8125, 0.824999988079071, 0.8270833492279053, 0.8010416626930237, 0.815625011920929, 0.8062499761581421, 0.8260416388511658, 0.796875, 0.8218749761581421, 0.8166666626930237, 0.7749999761581421, 0.8072916865348816, 0.8177083134651184, 0.8489583134651184, 0.793749988079071, 0.8197916746139526, 0.815625011920929, 0.7895833253860474, 0.8239583373069763, 0.7406250238418579, 0.8427083492279053, 0.8125, 0.8177083134651184, 0.796875, 0.8333333134651184, 0.828125, 0.778124988079071, 0.7833333611488342, 0.8364583253860474, 0.8374999761581421, 0.8395833373069763]
  loss = [0.8033788204193115, 0.7111012935638428, 0.6906856894493103, 0.6864686012268066, 0.6773087978363037, 0.6644845604896545, 0.6470198631286621, 0.6432424187660217, 0.6564621925354004, 0.612750232219696, 0.6241694688796997, 0.5956364870071411, 0.5991309285163879, 0.6025196313858032, 0.5869885683059692, 0.5915672779083252, 0.5817213654518127, 0.5808654427528381, 0.5692419409751892, 0.5690348744392395, 0.5583046078681946, 0.551440954208374, 0.5596482157707214, 0.5581054091453552, 0.5504767894744873, 0.5536369681358337, 0.5293948650360107, 0.5635769367218018, 0.5232992172241211, 0.5265769362449646, 0.5249305963516235, 0.534717321395874, 0.525932252407074, 0.5223432779312134, 0.5209355354309082, 0.5043962597846985, 0.5089579224586487, 0.49149757623672485, 0.5033844709396362, 0.481873482465744, 0.5084270238876343, 0.499146044254303, 0.4895784854888916, 0.4731656312942505, 0.48960429430007935, 0.47678276896476746, 0.4869554936885834, 0.4543050229549408, 0.48157015442848206, 0.46401217579841614, 0.4509909749031067, 0.45840075612068176, 0.4704005718231201, 0.47650399804115295, 0.46952110528945923, 0.454527348279953, 0.4473743736743927, 0.44839149713516235, 0.4499649703502655, 0.4769725501537323, 0.4534064531326294, 0.4439029395580292, 0.4438655376434326, 0.43106505274772644, 0.43320736289024353, 0.42887184023857117, 0.408588707447052, 0.4191901981830597, 0.4438486099243164, 0.4250383675098419, 0.40317070484161377, 0.4523426294326782, 0.4118388593196869, 0.45059725642204285, 0.41106319427490234, 0.43107831478118896, 0.4250001311302185, 0.43091845512390137, 0.41052231192588806, 0.4041123390197754, 0.40388068556785583, 0.42621850967407227, 0.40516170859336853, 0.3993919789791107, 0.42753416299819946, 0.3845365643501282, 0.4082501530647278, 0.42830270528793335, 0.3865119218826294, 0.4115617275238037, 0.4099297523498535, 0.3859091103076935, 0.3814539313316345, 0.3975774943828583, 0.3969041109085083, 0.377240389585495, 0.397799551486969, 0.3696751296520233, 0.3776901364326477, 0.3871661126613617]
  val_loss = [0.688431978225708, 0.6885424852371216, 0.6707516312599182, 0.6675980687141418, 0.6680215001106262, 0.6318312287330627, 0.6460374593734741, 0.6067062020301819, 0.638869047164917, 0.5905322432518005, 0.5741991400718689, 0.5486332178115845, 2.3399229049682617, 0.5724179744720459, 0.5938392877578735, 0.5385730862617493, 0.5152595043182373, 0.581160306930542, 0.5399463772773743, 0.5161529779434204, 0.5022844076156616, 0.5362760424613953, 0.6013532876968384, 0.4814072847366333, 0.5271319150924683, 0.6021125912666321, 0.5016552209854126, 0.4929943382740021, 0.45768216252326965, 0.47354361414909363, 1.152114987373352, 0.47685855627059937, 0.45301878452301025, 0.6487298607826233, 0.4783116579055786, 0.47576552629470825, 0.5320513844490051, 0.4366634488105774, 0.434565007686615, 0.5260101556777954, 0.5964476466178894, 0.4422931671142578, 0.627382218837738, 0.480959415435791, 0.5122424364089966, 0.4795341491699219, 0.523804783821106, 1.2073242664337158, 0.42600753903388977, 0.4675449728965759, 0.44096484780311584, 0.5384663343429565, 0.4880961775779724, 0.5306143164634705, 0.41208502650260925, 0.4190554916858673, 0.5258724689483643, 0.44707387685775757, 0.41781705617904663, 0.42553281784057617, 0.6109284162521362, 0.4694889187812805, 0.4225820004940033, 0.39798304438591003, 0.39495137333869934, 0.459619402885437, 0.5252389907836914, 0.3982768952846527, 0.41716888546943665, 0.46777838468551636, 0.46726295351982117, 0.4130536615848541, 0.6436124444007874, 0.439129501581192, 0.42771241068840027, 0.3782598674297333, 0.42986413836479187, 0.4417300224304199, 0.4699198603630066, 0.4934620261192322, 0.45442456007003784, 0.44030332565307617, 0.3782969117164612, 0.46531206369400024, 0.5222358107566833, 0.455170214176178, 0.4265991151332855, 0.44086214900016785, 0.6594657301902771, 0.3667616844177246, 0.4155740737915039, 0.43338051438331604, 0.4640316665172577, 0.384500116109848, 0.4694274961948395, 0.46059221029281616, 0.5106787085533142, 0.38906610012054443, 0.4015575051307678, 0.3905310332775116]

  plt.plot(range(1, len(acc) + 1), acc, 'bo', label='training acc')
  plt.plot(range(1, len(val_acc) + 1), val_acc, 'b', label='validation acc')
  plt.title('training and validation acc')
  plt.legend()

  plt.figure()

  plt.plot(range(1, len(loss) + 1), loss, 'bo', label='training loss')
  plt.plot(range(1, len(val_loss) + 1), val_loss, 'b', label='validation loss')
  plt.title('training and validation loss')
  plt.legend()

  plt.show()

def showDataEnhance():
  datagen = image.ImageDataGenerator(
    rescale=1.0/255, # 标准化数据，默认为 None。如果是 None 或 0，不进行缩放，否则将数据乘以所提供的值（在应用任何其他转换之前）
    rotation_range=40, # 随机旋转的度数范围
    width_shift_range=0.2, # 进行水平位移
    height_shift_range=0.2, # 进行垂直位移
    shear_range=0.2, # 剪切强度（以弧度逆时针方向剪切角度）
    zoom_range=0.2, # 随机缩放范围
    horizontal_flip=True, # 随机水平翻转
    fill_mode='nearest'
    )
  img = image.load_img('../../dataset/cats_and_dogs_small/train/cats/cat.3.jpg', target_size=(150, 150))
  x = image.img_to_array(img)
  x = x.reshape((1, 150, 150, 3))
  i = 0
  for batch in datagen.flow(x, batch_size=1):
    plt.figure(i)
    imgplot = plt.imshow(image.array_to_img(batch[0]))
    i += 1
    if i  % 4 == 0:
      break
  plt.show()

if __name__ == '__main__':
  print(tf.__version__)
  print(2000//32)

  c_vs_d_dataset = '../../dataset/cats_and_dogs_small'
  train_cats_dir = c_vs_d_dataset + '/train/cats'
  print('================================================')
  print('train cats count:', len(os.listdir(c_vs_d_dataset + '/train/cats')))
  print('train dogs count:', len(os.listdir(c_vs_d_dataset + '/train/dogs')))
  print('validation cats count:', len(os.listdir(c_vs_d_dataset + '/validation/cats')))
  print('validation dogs count:', len(os.listdir(c_vs_d_dataset + '/validation/dogs')))
  print('test cats count:', len(os.listdir(c_vs_d_dataset + '/test/cats')))
  print('test dogs count:', len(os.listdir(c_vs_d_dataset + '/test/dogs')))

  # 训练
  # train()

  # showHistory()
  showHistory2()

  # 数据增强
  # showDataEnhance()