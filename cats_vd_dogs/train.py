import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Activation, MaxPooling2D, Flatten, Dropout
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt

def load_data():
  """ 
  生成训练数据和
  """
  c_vs_d_dataset = '../../dataset/cats_and_dogs_small'
  # 输入目录的路径，并生成批量的增强/标准化的数据。
  train_datagen = image.ImageDataGenerator(
    rescale=1.0/255, # 标准化数据，默认为 None。如果是 None 或 0，不进行缩放，否则将数据乘以所提供的值（在应用任何其他转换之前）
    rotation_range=40, # 随机旋转的度数范围
    width_shift_range=0.2, # 进行水平位移
    height_shift_range=0.2, # 进行垂直位移
    shear_range=0.2, # 剪切强度（以弧度逆时针方向剪切角度）
    zoom_range=0.2, # 随机缩放范围
    horizontal_flip=True, # 随机水平翻转
    fill_mode='nearest'
    )
  test_datagen = image.ImageDataGenerator( rescale=1.0/255 )
  # 训练数据
  train_flow = train_datagen.flow_from_directory(directory=c_vs_d_dataset + '/train', target_size=(150, 150), batch_size=32, class_mode='binary')

  # 验证数据
  val_flow = test_datagen.flow_from_directory(directory=c_vs_d_dataset + '/validation', target_size=(150, 150), batch_size=32, class_mode='binary')
  return train_flow, val_flow


def createModel():
  # 搭建网络
  model = Sequential()

  # 第一层
  model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3)))
  model.add(MaxPooling2D(pool_size=(2, 2)))

  model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))
  model.add(MaxPooling2D(pool_size=(2, 2)))

  model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))
  model.add(MaxPooling2D(pool_size=(2, 2)))

  model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))
  model.add(MaxPooling2D(pool_size=(2, 2)))

  model.add(Flatten())
  model.add(Dropout(0.5))
  model.add(Dense(512, activation='relu'))
  model.add(Dense(1, activation='sigmoid'))

  model.summary()

  return model

def train():
  train_generator, val_generator = load_data()
  model = createModel()
  model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])
  history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=100, validation_data=val_generator, validation_steps=50)
  model.save('c_vs_d_small.h5')

  print(history.history.keys())
  acc = history.history['acc']
  val_acc = history.history['val_acc']
  loss = history.history['loss']
  val_loss = history.history['val_loss']

  print('--------------------------------------- acc', acc)
  print('--------------------------------------- val_acc', val_acc)
  print('--------------------------------------- loss', loss)
  print('--------------------------------------- val_loss', val_loss)

  # plt.plot(range(1, len(acc) + 1), acc, 'bo', label='training acc')
  # plt.plot(range(1, len(val_acc) + 1), val_acc, 'b', label='validation acc')
  # plt.title('training and validation acc')
  # plt.legend()

  # plt.figure()

  # plt.plot(range(1, len(loss) + 1), loss, 'bo', label='training loss')
  # plt.plot(range(1, len(val_loss) + 1), val_loss, 'b', label='validation loss')
  # plt.title('training and validation loss')
  # plt.legend()

  # plt.show()

def showHistory():
  acc = [0.5230000019073486, 0.5824999809265137, 0.6499999761581421, 0.7039999961853027, 0.7354999780654907, 0.7749999761581421, 0.7950000166893005, 0.8184999823570251, 0.859499990940094, 0.8960000276565552, 0.9169999957084656, 0.9355000257492065, 0.9580000042915344, 0.9610000252723694, 0.9695000052452087, 0.9735000133514404, 0.9725000262260437, 0.9804999828338623, 0.9835000038146973, 0.9810000061988831, 0.9854999780654907, 0.984000027179718, 0.9904999732971191, 0.9919999837875366, 0.9854999780654907, 0.9850000143051147, 0.9890000224113464, 0.9829999804496765, 0.9904999732971191, 0.9825000166893005]
  val_acc = [0.6320000290870667, 0.625, 0.6299999952316284, 0.6359999775886536, 0.7129999995231628, 0.7120000123977661, 0.7269999980926514, 0.656000018119812, 0.718999981880188, 0.7250000238418579, 0.703000009059906, 0.6809999942779541, 0.7329999804496765, 0.7289999723434448, 0.7369999885559082, 0.7160000205039978, 0.7319999933242798, 0.7059999704360962, 0.6430000066757202, 0.7110000252723694, 0.7129999995231628, 0.7160000205039978, 0.6990000009536743, 0.7260000109672546, 0.7269999980926514, 0.718999981880188, 0.722000002861023, 0.7120000123977661, 0.7200000286102295, 0.6990000009536743]
  loss = [0.7197771668434143, 0.7057441473007202, 0.6319062113761902, 0.573307454586029, 0.5296744704246521, 0.4704899489879608, 0.4317125678062439, 0.38529062271118164, 0.3259923756122589, 0.2635868191719055, 0.2121836245059967, 0.15839920938014984, 0.11766181141138077, 0.10165029764175415, 0.0895504504442215, 0.07623737305402756, 0.07694771140813828, 0.07092680037021637, 0.06741562485694885, 0.06424108147621155, 0.0475294329226017, 0.05646130442619324, 0.04277775064110756, 0.04779304936528206, 0.057735342532396317, 0.06555821746587753, 0.045323267579078674, 0.06264374405145645, 0.04166410490870476, 0.06865067780017853]
  val_loss = [0.6834479570388794, 0.640883207321167, 0.6846174597740173, 0.6827576160430908, 0.5608593821525574, 0.6068069934844971, 0.5495100617408752, 1.11831533908844, 0.6583135724067688, 0.751167893409729, 1.0499873161315918, 1.4772028923034668, 1.2145891189575195, 1.3855600357055664, 1.4357553720474243, 1.4306654930114746, 1.9696789979934692, 2.0970659255981445, 4.278090476989746, 2.4249448776245117, 2.5412590503692627, 2.4847662448883057, 2.6638028621673584, 3.5236270427703857, 2.8296263217926025, 2.8235323429107666, 4.714761257171631, 2.0557870864868164, 5.017805576324463, 3.289170026779175]

  plt.plot(range(1, len(acc) + 1), acc, 'bo', label='training acc')
  plt.plot(range(1, len(val_acc) + 1), val_acc, 'b', label='validation acc')
  plt.title('training and validation acc')
  plt.legend()

  plt.figure()

  plt.plot(range(1, len(loss) + 1), loss, 'bo', label='training loss')
  plt.plot(range(1, len(val_loss) + 1), val_loss, 'b', label='validation loss')
  plt.title('training and validation loss')
  plt.legend()

  plt.show()

def showHistory2():
  acc = [0.5110294222831726, 0.5152310729026794, 0.555672287940979, 0.5477941036224365, 0.5877100825309753, 0.6081932783126831, 0.6486344337463379, 0.6391806602478027, 0.6365545988082886, 0.6670168042182922, 0.6538865566253662, 0.6706932783126831, 0.6780462265014648, 0.6875, 0.6780462265014648, 0.6922268867492676, 0.7016806602478027, 0.6843487620353699, 0.7195377945899963, 0.7127100825309753, 0.7153361439704895, 0.7247899174690247, 0.7043067216873169, 0.7158613204956055, 0.7211134433746338, 0.7153361439704895, 0.7352941036224365, 0.7158613204956055, 0.7494747638702393, 0.7405462265014648, 0.7410714030265808, 0.7452731132507324, 0.7447478771209717, 0.7457982897758484, 0.7473739385604858, 0.7536764740943909, 0.7584033608436584, 0.7515756487846375, 0.7505252361297607, 0.7778361439704895, 0.7620798349380493, 0.7668067216873169, 0.7636554837226868, 0.786239504814148, 0.7647058963775635, 0.7752100825309753, 0.7657563090324402, 0.7878151535987854, 0.7710084319114685, 0.7715336084365845, 0.7935924530029297, 0.7932291626930237, 0.7883403301239014, 0.7736344337463379, 0.7867646813392639, 0.8019958138465881, 0.796875, 0.8014705777168274, 0.7998949289321899, 0.7867646813392639, 0.7878151535987854, 0.8077731132507324, 0.7956932783126831, 0.8156512379646301, 0.815625011920929, 0.805672287940979, 0.8151260614395142, 0.8172268867492676, 0.8051470518112183, 0.8125, 0.8198529481887817, 0.8019958138465881, 0.8088235259056091, 0.7972689270973206, 0.8140756487846375, 0.8040966391563416, 0.8098739385604858, 0.8130252361297607, 0.825630247592926, 0.8172268867492676, 0.8266806602478027, 0.8182772994041443, 0.8240545988082886, 0.8230041861534119, 0.8156512379646301, 0.8293067216873169, 0.8277310729026794, 0.8198529481887817, 0.8293067216873169, 0.8282563090324402, 0.8219537734985352, 0.8371848464012146, 0.8277310729026794, 0.832457959651947, 0.8251050710678101, 0.8303571343421936, 0.8261554837226868, 0.8413865566253662, 0.8308823704719543, 0.8356092572212219]
  val_acc = [0.49687498807907104, 0.5458333492279053, 0.6135416626930237, 0.6239583492279053, 0.6156250238418579, 0.625, 0.5708333253860474, 0.6739583611488342, 0.6333333253860474, 0.6822916865348816, 0.7093750238418579, 0.7197916507720947, 0.5104166865348816, 0.7093750238418579, 0.6854166388511658, 0.7177083492279053, 0.746874988079071, 0.6760416626930237, 0.7260416746139526, 0.7333333492279053, 0.746874988079071, 0.7302083373069763, 0.6989583373069763, 0.7854166626930237, 0.7270833253860474, 0.7239583134651184, 0.7552083134651184, 0.7739583253860474, 0.7906249761581421, 0.7864583134651184, 0.6552083492279053, 0.7729166746139526, 0.7947916388511658, 0.6572916507720947, 0.7645833492279053, 0.7729166746139526, 0.7427083253860474, 0.8041666746139526, 0.7906249761581421, 0.7614583373069763, 0.7197916507720947, 0.7989583611488342, 0.715624988079071, 0.8020833134651184, 0.7895833253860474, 0.7718750238418579, 0.7635416388511658, 0.6760416626930237, 0.8125, 0.7791666388511658, 0.8125, 0.768750011920929, 0.7604166865348816, 0.7489583492279053, 0.8052083253860474, 0.815625011920929, 0.7770833373069763, 0.8072916865348816, 0.8083333373069763, 0.8270833492279053, 0.7124999761581421, 0.8125, 0.8125, 0.8197916746139526, 0.8333333134651184, 0.8135416507720947, 0.7666666507720947, 0.8177083134651184, 0.8125, 0.8125, 0.824999988079071, 0.8270833492279053, 0.8010416626930237, 0.815625011920929, 0.8062499761581421, 0.8260416388511658, 0.796875, 0.8218749761581421, 0.8166666626930237, 0.7749999761581421, 0.8072916865348816, 0.8177083134651184, 0.8489583134651184, 0.793749988079071, 0.8197916746139526, 0.815625011920929, 0.7895833253860474, 0.8239583373069763, 0.7406250238418579, 0.8427083492279053, 0.8125, 0.8177083134651184, 0.796875, 0.8333333134651184, 0.828125, 0.778124988079071, 0.7833333611488342, 0.8364583253860474, 0.8374999761581421, 0.8395833373069763]
  loss = [0.8033788204193115, 0.7111012935638428, 0.6906856894493103, 0.6864686012268066, 0.6773087978363037, 0.6644845604896545, 0.6470198631286621, 0.6432424187660217, 0.6564621925354004, 0.612750232219696, 0.6241694688796997, 0.5956364870071411, 0.5991309285163879, 0.6025196313858032, 0.5869885683059692, 0.5915672779083252, 0.5817213654518127, 0.5808654427528381, 0.5692419409751892, 0.5690348744392395, 0.5583046078681946, 0.551440954208374, 0.5596482157707214, 0.5581054091453552, 0.5504767894744873, 0.5536369681358337, 0.5293948650360107, 0.5635769367218018, 0.5232992172241211, 0.5265769362449646, 0.5249305963516235, 0.534717321395874, 0.525932252407074, 0.5223432779312134, 0.5209355354309082, 0.5043962597846985, 0.5089579224586487, 0.49149757623672485, 0.5033844709396362, 0.481873482465744, 0.5084270238876343, 0.499146044254303, 0.4895784854888916, 0.4731656312942505, 0.48960429430007935, 0.47678276896476746, 0.4869554936885834, 0.4543050229549408, 0.48157015442848206, 0.46401217579841614, 0.4509909749031067, 0.45840075612068176, 0.4704005718231201, 0.47650399804115295, 0.46952110528945923, 0.454527348279953, 0.4473743736743927, 0.44839149713516235, 0.4499649703502655, 0.4769725501537323, 0.4534064531326294, 0.4439029395580292, 0.4438655376434326, 0.43106505274772644, 0.43320736289024353, 0.42887184023857117, 0.408588707447052, 0.4191901981830597, 0.4438486099243164, 0.4250383675098419, 0.40317070484161377, 0.4523426294326782, 0.4118388593196869, 0.45059725642204285, 0.41106319427490234, 0.43107831478118896, 0.4250001311302185, 0.43091845512390137, 0.41052231192588806, 0.4041123390197754, 0.40388068556785583, 0.42621850967407227, 0.40516170859336853, 0.3993919789791107, 0.42753416299819946, 0.3845365643501282, 0.4082501530647278, 0.42830270528793335, 0.3865119218826294, 0.4115617275238037, 0.4099297523498535, 0.3859091103076935, 0.3814539313316345, 0.3975774943828583, 0.3969041109085083, 0.377240389585495, 0.397799551486969, 0.3696751296520233, 0.3776901364326477, 0.3871661126613617]
  val_loss = [0.688431978225708, 0.6885424852371216, 0.6707516312599182, 0.6675980687141418, 0.6680215001106262, 0.6318312287330627, 0.6460374593734741, 0.6067062020301819, 0.638869047164917, 0.5905322432518005, 0.5741991400718689, 0.5486332178115845, 2.3399229049682617, 0.5724179744720459, 0.5938392877578735, 0.5385730862617493, 0.5152595043182373, 0.581160306930542, 0.5399463772773743, 0.5161529779434204, 0.5022844076156616, 0.5362760424613953, 0.6013532876968384, 0.4814072847366333, 0.5271319150924683, 0.6021125912666321, 0.5016552209854126, 0.4929943382740021, 0.45768216252326965, 0.47354361414909363, 1.152114987373352, 0.47685855627059937, 0.45301878452301025, 0.6487298607826233, 0.4783116579055786, 0.47576552629470825, 0.5320513844490051, 0.4366634488105774, 0.434565007686615, 0.5260101556777954, 0.5964476466178894, 0.4422931671142578, 0.627382218837738, 0.480959415435791, 0.5122424364089966, 0.4795341491699219, 0.523804783821106, 1.2073242664337158, 0.42600753903388977, 0.4675449728965759, 0.44096484780311584, 0.5384663343429565, 0.4880961775779724, 0.5306143164634705, 0.41208502650260925, 0.4190554916858673, 0.5258724689483643, 0.44707387685775757, 0.41781705617904663, 0.42553281784057617, 0.6109284162521362, 0.4694889187812805, 0.4225820004940033, 0.39798304438591003, 0.39495137333869934, 0.459619402885437, 0.5252389907836914, 0.3982768952846527, 0.41716888546943665, 0.46777838468551636, 0.46726295351982117, 0.4130536615848541, 0.6436124444007874, 0.439129501581192, 0.42771241068840027, 0.3782598674297333, 0.42986413836479187, 0.4417300224304199, 0.4699198603630066, 0.4934620261192322, 0.45442456007003784, 0.44030332565307617, 0.3782969117164612, 0.46531206369400024, 0.5222358107566833, 0.455170214176178, 0.4265991151332855, 0.44086214900016785, 0.6594657301902771, 0.3667616844177246, 0.4155740737915039, 0.43338051438331604, 0.4640316665172577, 0.384500116109848, 0.4694274961948395, 0.46059221029281616, 0.5106787085533142, 0.38906610012054443, 0.4015575051307678, 0.3905310332775116]

  plt.plot(range(1, len(acc) + 1), acc, 'bo', label='training acc')
  plt.plot(range(1, len(val_acc) + 1), val_acc, 'b', label='validation acc')
  plt.title('training and validation acc')
  plt.legend()

  plt.figure()

  plt.plot(range(1, len(loss) + 1), loss, 'bo', label='training loss')
  plt.plot(range(1, len(val_loss) + 1), val_loss, 'b', label='validation loss')
  plt.title('training and validation loss')
  plt.legend()

  plt.show()

def showDataEnhance():
  datagen = image.ImageDataGenerator(
    rescale=1.0/255, # 标准化数据，默认为 None。如果是 None 或 0，不进行缩放，否则将数据乘以所提供的值（在应用任何其他转换之前）
    rotation_range=40, # 随机旋转的度数范围
    width_shift_range=0.2, # 进行水平位移
    height_shift_range=0.2, # 进行垂直位移
    shear_range=0.2, # 剪切强度（以弧度逆时针方向剪切角度）
    zoom_range=0.2, # 随机缩放范围
    horizontal_flip=True, # 随机水平翻转
    fill_mode='nearest'
    )
  img = image.load_img('../../dataset/cats_and_dogs_small/train/cats/cat.3.jpg', target_size=(150, 150))
  x = image.img_to_array(img)
  x = x.reshape((1, 150, 150, 3))
  i = 0
  for batch in datagen.flow(x, batch_size=1):
    plt.figure(i)
    imgplot = plt.imshow(image.array_to_img(batch[0]))
    i += 1
    if i  % 4 == 0:
      break
  plt.show()

if __name__ == '__main__':
  print(tf.__version__)
  print(2000//32)

  c_vs_d_dataset = '../../dataset/cats_and_dogs_small'
  train_cats_dir = c_vs_d_dataset + '/train/cats'
  print('================================================')
  print('train cats count:', len(os.listdir(c_vs_d_dataset + '/train/cats')))
  print('train dogs count:', len(os.listdir(c_vs_d_dataset + '/train/dogs')))
  print('validation cats count:', len(os.listdir(c_vs_d_dataset + '/validation/cats')))
  print('validation dogs count:', len(os.listdir(c_vs_d_dataset + '/validation/dogs')))
  print('test cats count:', len(os.listdir(c_vs_d_dataset + '/test/cats')))
  print('test dogs count:', len(os.listdir(c_vs_d_dataset + '/test/dogs')))

  # 训练
  train()

  # showHistory()
  # showHistory2()

  # 数据增强
  # showDataEnhance()